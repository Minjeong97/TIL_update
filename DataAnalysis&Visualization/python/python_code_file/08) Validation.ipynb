{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "255764e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\samsung\\appdata\\roaming\\python\\python310\\site-packages (1.1.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\samsung\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\samsung\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.9.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\samsung\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\samsung\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.23.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "# 아이리스\n",
    "from sklearn.datasets import load_iris\n",
    "# 의사결정나무\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# 평가지표\n",
    "from sklearn.metrics import accuracy_score as acc_sc  # alias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14871bb",
   "metadata": {},
   "source": [
    "### 만약 데이터를 쪼개지 않고 통으로 한다면,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b4b56b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "X_data = iris.data # X = 독립변수 = 설명변수 = feature(머신러닝) \n",
    "y_target = iris.target # y = 종속변수(이산) = target = label\n",
    "\n",
    "## 의사결정나무 객체화 \n",
    "dt_clf = DecisionTreeClassifier()  # Black Box 설정 == 알고리즘 (어떤 규칙을 찾음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f534e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_data.copy()\n",
    "y_train = y_target.copy()\n",
    "\n",
    "# 학습 수행 - 데이터 분할 X\n",
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4268f1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 수행\n",
    "y_pred = dt_clf.predict(X_train)  # 2차원의 입력 X값이 들어와야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a69c6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 평가지표로 평가 - acc_sc\n",
    "print(f'예측 정확도: {acc_sc(y_train, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac3b76d",
   "metadata": {},
   "source": [
    "### '예측 정확도: 1.0' 이 나온 이유\n",
    "원래는 X_data - (Black Box) - Y_target 구성이었음.\n",
    "\n",
    "Black Box 안에다가 X_train & y_train 를 넣었음.\n",
    "\n",
    "여기서 X_train은 모든 독립변수 각각을 모두 합한 상태를 복사해서 넣었기 때문에 y_target과 y_pred 값이 당연히 같게 나옴 (acc_sc = 1)\n",
    "\n",
    "따라서 학습을 시킬 때, X_data에서 X_test를 추출하고 y_train에서 y_test를 추출해서 분리 데이터를 만들고 -> Black Box에 넣어서 predict -> 'y_test = y_actual'가 되고, X_test로 예측한 y_pred가 나옴 -> y_pred와 y_test(ay_actual)를 비교! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d17d83",
   "metadata": {},
   "source": [
    "### 데이터를 쪼개서 예측할 때,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3211be97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 이렇게 train과 test 두 가지를 분리하는 것을 Hold_out(홀드아웃)이라고 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "326de76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "array_1 = np.arange(1,11)\n",
    "array_11 = np.arange(11,21)\n",
    "\n",
    "### 연습\n",
    "# train_test_split(array_1, test_size=0.2)  # default=25%, train값은 50% 이상이어야 함.\n",
    "# 이 상태에서는 클릭할 때마다 값이 바뀜. 만약 고정시키고 싶다면,\n",
    "\n",
    "# train1, test1 = train_test_split(array_1, test_size=0.2, random_state=121)  # 보통은 random_state 값은 400 미만의 숫자 아무거나 \n",
    "# train11, test11 = train_test_split(array_11, test_size=0.2, random_state=121) \n",
    "# # 위 두줄을 한 줄로 줄이면,\n",
    "train1, test1, train11, test11 = train_test_split(array_1, array_11, test_size=0.2, random_state=121)  # 보통은 random_state 값은 400 미만의 숫자 아무거나 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e7d6bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다시 본문으로 돌아와서..\n",
    "# X와 y 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_target, test_size=0.2, random_state=121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0fb973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 재학습\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "## 예측 수행\n",
    "y_pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b7504b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 평가지표\n",
    "acc_sc(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea018727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측정확도: 0.967\n"
     ]
    }
   ],
   "source": [
    "print(f'예측정확도: {np.round(acc_sc(y_test, y_pred), 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca63975",
   "metadata": {},
   "source": [
    "## Validation (교차검증)\n",
    "\n",
    "#### 과적합(Overfitting)\n",
    "\n",
    "현재 우리는 'test_size=0.2, random_state=121'로 고정시켜서 했다.\n",
    "\n",
    "이 경우, 과적합(overfitting)의 위험에서 벗어날 수 없다. (과적합되는 것을 피해야 함.)\n",
    "\n",
    "따라서 '교차검증'을 통해서 해결해보자.\n",
    "\n",
    "그렇다면, '교차검증'이란 무엇인가?\n",
    "    \n",
    "    - Validation을 여러번 하는 것. --> validation을 한 번만 하면 overfitting될 수 있어서 여러번 하는 것!\n",
    "    - 그렇다면, Validation을 어떻게 할 것인가? ex) k-fold 방법 :: k를 내가 정할 수 있다. \n",
    "    - * (마치 종이접기하는 것처럼 전체 train 데이터를 k개로 나누기)\n",
    "\n",
    "\n",
    "#### 참고)\n",
    "\n",
    "- test 데이터는 만들고 나서는 절대 건들지 말 것\n",
    "- train 데이터를 쪼개서 다른 test 데이터를 만들기 ==> Validation 데이터 생성 ==> 그러면 original train = train(2/3만큼) 데이터 + validation 데이터\n",
    "- Validation 데이터를 가지고 Black Box에 넣어서 학습 시킨다. 이 때, train(2/3) 데이터는 학습한 후에 삭제.\n",
    "- Validation 데이터로 학습시킨 결과값인 pred_val를 test 데이터와 비교\n",
    "\n",
    "#### 교차검증 과정 설명\n",
    "\n",
    "- k := 하이퍼파라미터 (사람이 정하는 것)\n",
    "- k = 5 로 지정하면, original train에서 'train 데이터 + validation 데이터' 세트가 5개로 쪼개짐. (보통은 10번 돌림.)\n",
    "\n",
    "- CV := Cross Validation (교차검증) ==> 사람이 데이터를 섞어서 검증하는 것\n",
    "\n",
    "    - CV = 1 := 첫번째 k 데이터셋을 validation으로, 나머지 4개를 train으로.\n",
    "    - CV = 2 := 두번째 k 데이터셋을 validation으로, 나머지 4개를 train으로.\n",
    "    - ... \n",
    "    - CV = 5 까지 진행\n",
    "\n",
    "총 5번의 validation이 수행됨.\n",
    "\n",
    "따라서, k = CV = 5\n",
    "\n",
    "즉, k는 내가 정하고, CV는 k와 동일하게 설정되는 것.\n",
    "\n",
    "\n",
    "##### test 데이터를 건드릴 수 없으니, train 데이터에서 validation 데이터를 통해 가상의 test를 만들어 진행하고, black box의 알고리즘을 통해 predict하는 것.\n",
    "\n",
    "##### test와 train 데이터 안에는 x, y 모두 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0331c2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Validation 설정\n",
    "\n",
    "# 라이브러리 호출 순서 (권장)\n",
    "# 데이터 관련 함수 - 모델 셀렉션(model_selection 관련: train_test_split) - 필요한 알고리즘 호출: 의사결정나무, 랜덤포레스트 \n",
    "\n",
    "# 필수 라이브러리 호출\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold  # overfitting 피하려고 사용하는 라이브러리\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score as acc_sc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0c95fd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋의 크기: 150\n"
     ]
    }
   ],
   "source": [
    "# 데이터 재정의: 앞서 했던 거 말고 새롭게!\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data # X값\n",
    "label = iris.target  # y값\n",
    "\n",
    "# 알고리즘 객체화\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "# kfold에서 k = 5\n",
    "kfold = KFold(n_splits=5)\n",
    "print('데이터셋의 크기:', features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "49e1167e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " #1 CV 정확도: 1.0, 학습데이터 크기: 120, 검증데이터 크기: 30\n",
      "#1 검증데이터셋 인덱스: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      " #2 CV 정확도: 0.967, 학습데이터 크기: 120, 검증데이터 크기: 30\n",
      "#2 검증데이터셋 인덱스: [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "\n",
      " #3 CV 정확도: 0.867, 학습데이터 크기: 120, 검증데이터 크기: 30\n",
      "#3 검증데이터셋 인덱스: [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "\n",
      " #4 CV 정확도: 0.933, 학습데이터 크기: 120, 검증데이터 크기: 30\n",
      "#4 검증데이터셋 인덱스: [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      " #5 CV 정확도: 0.733, 학습데이터 크기: 120, 검증데이터 크기: 30\n",
      "#5 검증데이터셋 인덱스: [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      " ## 평균 CV 정확도: 0.9\n"
     ]
    }
   ],
   "source": [
    "cv_accuracy = []\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, val_index in kfold.split(label):\n",
    "    # Kfold.split()으로 반환된 인덱스를 통해 학습용, 검증용 데이터 정의\n",
    "    X_train, X_val = features[train_index], features[val_index]\n",
    "    y_train, y_val  = label[train_index], label[val_index]\n",
    "    \n",
    "    # 각 CV별 학습 및 예측\n",
    "    dt_clf.fit(X_train,y_train) # 학습\n",
    "    pred = dt_clf.predict(X_val) # 예측\n",
    "    \n",
    "    # 정확도 지표 계산\n",
    "    accuracy = np.round(acc_sc(y_val, pred), 3)\n",
    "    train_size = X_train.shape[0]\n",
    "    val_size = X_val.shape[0]\n",
    "    n_iter += 1\n",
    "    print(f'\\n #{n_iter} CV 정확도: {accuracy}, 학습데이터 크기: {train_size}, 검증데이터 크기: {val_size}')\n",
    "    print(f'#{n_iter} 검증데이터셋 인덱스: {val_index}')\n",
    "    cv_accuracy.append(accuracy)\n",
    "\n",
    "# 개별 iteration 별 정확도 평균내기\n",
    "print(f'\\n ## 평균 CV 정확도: {np.mean(cv_accuracy)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892c0a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
